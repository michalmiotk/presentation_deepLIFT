<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta name="author" content="Michal Miotk">

  <title>DeepLIFT</title>

  <link rel="stylesheet" href="dist/reset.css">
  <link rel="stylesheet" href="dist/reveal.css">
  <link rel="stylesheet" href="dist/theme/black.css" id="theme">

  <!-- Theme used for syntax highlighting of code -->
  <link rel="stylesheet" href="css/highlight/isbl-editor-light.css">
</head>
<body>
<div class="reveal">
  <div class="slides">
    <section>
      <h4>basics of DeepLIFT</h4>
      <p>Micha≈Ç Miotk</p>
    </section>
    <section>
      <p>Agenda</p>
      <ol>
        <li>Short introduction</li>
        <li>DeepLIFT history</li>
        <li>Which problem DeepLIFT solve?</li>
        <li>When DeepLIFT fails?</li>
        <li>Demo</li>
        <li>Future work</li>
        <li>Links</li>
      </ol> 
    </section>
    <section>
      <section>
      <p>DeepLIFT history</p>
      Everything starts 2016 paper from Stanford which already describes basics concept: 
      <blockquote>Not Just A Black Box:Interpretable Deep Learning by Propagating Activation Differences</blockquote>
      this paper not fully describes concept, new release in 2019 give more lights:
      <blockquote>Learning Important Features Through Propagating Activation Differences</blockquote>
      </section>
      <section>
        <img src="images/features.png" />
        <p>Image from 2019 paper</p>
      </section> 
      <section>       
        <img src="images/calc.png"/>
        <p>Image describing multiplier calculation</p>
      </section>
      <section>
        <p>Image from TOWARDS BETTER UNDERSTANDING OFGRADIENT-BASED ATTRIBUTION METHODS FOR DEEP NEURAL NETWORKS</p>
        <img src="images/openreview.png"/>
      </section>
    </section>
    <section>
      <section>
      <h4>When DeepLIFT fails?</h4>
      <p>DeepLIFT not satisfy axiom -  Implementation Invariance - if two different neural networks gives for same inputs same outputs
        predictions should be the same
      </p>
    </section>
    <section>
      <h4>When DeepLIFT fails?</h4>
      <img src="images/break_axiom.png"/>
      <p>image from Axiomatic Attribution for Deep Networks</p>
    </section>
    </section>
    <section>
      <section>
        <h3>Future work - pruning from Utilizing Explainable AI for Quantization and Pruning of Deep Neural Networks </h3>
        <img src="images/pruning.png">
      </section>
      <section>
        <h3>Future work - pruning </h3>
        <p>DLP has better results because it also additionaly takes into consideration impact of layer to output</p>
        <p>L1 takes only impact of neuron to layer</p>
      </section>
    </section>
    <section>
      <section>
        <h4>Links</h4>
        <ul>
          <li>first paper in 2016: https://arxiv.org/pdf/1605.01713v1.pdf</li>
          <li>paper from 2019 https://arxiv.org/pdf/1704.02685.pdf</li>
          <li>TOWARDS BETTER UNDERSTANDING OFGRADIENT-BASED ATTRIBUTION METHODS FOR DEEP NEURAL NETWORKS https://openreview.net/pdf?id=Sy21R9JAW</li>
          <li>Axiomatic Attribution for Deep Networks https://arxiv.org/pdf/1703.01365.pdf</li>
         </ul>
      </section>
      <section>
        <h4>Links</h4>
        <ul>
          <li>Utilizing Explainable AI for Quantization and Pruning of Deep Neural Networks https://arxiv.org/pdf/2008.09072.pdf</li>
        </ul>
      </section>
    </section>
    <section>
      <h2>Thanks</h2>
      <blockquote>"There's no such thing as a stupid question!"</blockquote>
    </section>
  </div>
</div>



<script src="dist/reveal.js"></script>
<script src="plugin/notes/notes.js"></script>
<script src="plugin/markdown/markdown.js"></script>
<script src="plugin/highlight/highlight.js"></script>
<script src="plugin/math/math.js"></script>
<script>
  // More info about config & dependencies:
  // - https://github.com/hakimel/reveal.js#configuration
  // - https://github.com/hakimel/reveal.js#dependencies
  Reveal.initialize({
    hash: true,
    controls: true,
    progress: true,
    slideNumber: false,
    overview: true,
    center: true,
    navigationMode: 'default',
    fragmentInURL: false,
    embedded: false,
    preloadIframes: null,
    autoSlide: 0,
    autoSlideStoppable: true,
    defaultTiming: 120,
    mouseWheel: false,
    previewLinks: false,
    transition: 'slide', // none/fade/slide/convex/concave/zoom
    transitionSpeed: 'default', // default/fast/slow
    backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom
    display: 'block',
    math: {
      mathjax: 'plugin/math/MathJax.js',
      config: 'TeX-AMS_HTML-full', // See http://docs.mathjax.org/en/latest/config-files.html
      // pass other options into `MathJax.Hub.Config()`
      TeX: { Macros: { RR: "{\\bf R}" } }
    },
    plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
  });
</script>
</body>
</html>
